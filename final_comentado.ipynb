{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASIFICADORES DE MNIST FASHION \n",
    "\n",
    "10 Clases de ropa\n",
    "\n",
    "['Camiseta', 'Pantalon', 'Jersey', 'Vestido', 'Abrigo', 'Sandalia', 'Camisa', 'Zapatilla', 'Bolso', 'Bota']\n",
    "\n",
    "## Clasificadores usados:\n",
    "- SVM (Scikit-learn)\n",
    "- Red neuronal multicapa , MLP. (Tensorflow y Scikit-learn)\n",
    "- OVO (Scikit-learn)\n",
    "\n",
    "## Accuracys por clasificador \n",
    "|    |  SVM  |  MLP (Scikit-learn) | MLP (Tensorflow)  | OVO (SVM)  | \n",
    "|--- |---    |---    |---     |---     |\n",
    "|  Acc (% )  |   89%    |  87%    |  87%    |   | \n",
    "\n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias para el correcto funcionamiento del programa.\n",
    "\n",
    "En caso de no tenerlas instaladas ejecutar siguiente comando:\n",
    "\n",
    "`pip install -r requirements.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura del dataset \"FASHION-MNIST\"\n",
    "\n",
    "Fashion-MNIST es un conjunto de datos de imágenes de artículos de Zalando que consta de un conjunto de entrenamiento de 60.000 ejemplos y un conjunto de prueba de 10.000 ejemplos. Cada ejemplo es una imagen en escala de grises de 28x28 asociada a una etiqueta de 10 clases. \n",
    "\n",
    "- Tamaño de imagen: 28x28\n",
    "- Numero de imagenes train: 60000\n",
    "- Numero de imagenes test: 10000\n",
    "- Numero de clases: 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.loadtxt(\"archive/fashion-mnist_test.csv\", delimiter=',', skiprows=1)\n",
    "train = np.loadtxt(\"archive/fashion-mnist_train.csv\",\n",
    "                   delimiter=',', skiprows=1)\n",
    "\n",
    "test = test[1:]\n",
    "train = train[1:]\n",
    "\n",
    "data = np.vstack((train, test))\n",
    "\n",
    "X = data[:, 1:]\n",
    "y = data[:, 0]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y, dtype=np.uint8)\n",
    "\n",
    "\n",
    "print(\"Numero ejemplos test: \",len(test))\n",
    "print(\"Numero ejemplos train: \",len(train))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos del dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases = ['Camiseta', 'Pantalon', 'Jersey', 'Vestido', 'Abrigo',\n",
    "          'Sandalia', 'Camisa', 'Zapatilla', 'Bolso', 'Bota']\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X[i].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.xlabel(clases[int(y[i])])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso del ShullfeSplit de Scikit-learn para dividir los datos en un conjunto deseado.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ShuffleSplit(n_splits=10, test_size=.20, random_state=0)\n",
    "for train_index, test_index in rs.split(X, y):\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "\n",
    "print(\"SHAPE Xtrain\", X_train.shape)\n",
    "print(\"SHAPE y_train\", y_train.shape)\n",
    "print(\"SHAPE X_test\", X_test.shape)\n",
    "print(\"SHAPE y_test\", y_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLSIFICADOR 1: SVM (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy SVM : \"+str(accuracy_score(y_test, y_pred)))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de imagenes mal clasificadas\n",
    "\n",
    "Alterando la variable size se cambia el numero de ejemplos mal clasificados que se quiera mostrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(y_pred != y_test).ravel()\n",
    "X_mal = X_test[mask]\n",
    "y_mal = y_test[mask]\n",
    "y_pred_mal = y_pred[mask]\n",
    "\n",
    "size = 100\n",
    "col = 5\n",
    "row = int(np.ceil(size / col))\n",
    "fig, axes = plt.subplots(row, col, figsize=(2*2*col, 2*row))\n",
    "\n",
    "for degree in range(size):\n",
    "    index = np.random.randint(0, X_mal.shape[0])\n",
    "    img = X_mal[index, :].reshape(28, 28)\n",
    "    axes.ravel()[degree].imshow(img, cmap=plt.cm.gray)\n",
    "    axes.ravel()[degree].set_title(\n",
    "        f'Class: {clases[int(y_mal.flat[index])]}  Predict: {clases[int(y_pred_mal.flat[index])]}')\n",
    "    axes.ravel()[degree].axis('off')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafico de barras mostrando el numero de fallos por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.arange(10)\n",
    "valores = np.zeros(10)\n",
    "for i in range(10):\n",
    "    valores[i] = np.sum(y_pred[mask] == i)\n",
    "plt.bar(classes, valores)\n",
    "\n",
    "plt.xticks(classes, ['Camiseta', 'Pantalon', 'Jersey', 'Vestido', 'Abrigo', 'Sandalia', 'Camisa', 'Zapatilla', 'Bolso', 'Bota'])\n",
    "plt.xlabel('Tipo de ropa')\n",
    "plt.ylabel('Numero de fallos')\n",
    "plt.title(\"Fallos por clase\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASIFICADOR 2: MLP (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = range(1, 70, 10)\n",
    "accuracies = np.zeros(len(hidden_sizes))\n",
    "\n",
    "for s, size in enumerate(hidden_sizes):\n",
    "    # Crea el clasificador con size neuronas en la capa oculta.\n",
    "    # Después entrénalo, y obten la precisión en los datos de entrenamiento.\n",
    "    # Guarda la precisión final en una variable accTrain.\n",
    "    clasificador = MLPClassifier(hidden_layer_sizes=(\n",
    "        size, 20, 10), solver='adam', max_iter=2000, alpha=0.01)\n",
    "\n",
    "    clasificador.fit(X_train, y_train.ravel())\n",
    "\n",
    "    y_pred = clasificador.predict(X_test)\n",
    "\n",
    "    accTrain = accuracy_score(y_pred, y_test)\n",
    "\n",
    "    accuracies[s] = accTrain\n",
    "\n",
    "print('Max accuracy con:', hidden_sizes[np.argmax(accuracies)])\n",
    "print(max(accuracies))\n",
    "# Muestra en una gráfica como ha cambiado el error conforme aumentábamos hidden_sizes\n",
    "plt.plot(hidden_sizes, accuracies)\n",
    "plt.xlabel('hidden_sizes')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CON EL TAMAÑO OPTIMO DE CAPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador = MLPClassifier(hidden_layer_sizes=(\n",
    "    65, 20, 15, 10), solver='adam', max_iter=3000, alpha=0.001)\n",
    "\n",
    "clasificador.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred = clasificador.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \"+str(accuracy_score(y_test, y_pred)))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASIFICADOR 3: MLP (Tensorflow)\n",
    "\n",
    "Hemos usado Tensorflow ya que es mucho mas rapido (al usar gpu)  y mas facil de implementar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen los datos  con una utilidad de keras, ya que el dataset ya viene incluido con la libreria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se convierten los datos a un rango [0,1] y las clases a numeros entre [0,9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la red neuronal con sus respectivas capas y funciones de activación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=2000, epochs=10,shuffle = 1,validation_split = 0.2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=0)\n",
    "print('test loss, test acc:', results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
